{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from itertools import product\n",
    "from os import remove\n",
    "from os.path import isfile\n",
    "import sqlite3\n",
    "import subprocess\n",
    "\n",
    "db_fname = '../../hmt.db'\n",
    "# audio directory, put stereo files in \"orig/\" subdirectory and create\n",
    "# empty \"split/\" subdirectory for mono\n",
    "audio_dir = '/media/andi/1E42EC061079D2FE/map_task_corpus_hebrew/'\n",
    "tmp_dir = '/media/andi/1E42EC061079D2FE/tmp/'\n",
    "meta_dir = '../../data/meta/'\n",
    "trans_dir = '../../data/trans/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run init script to create empty tables\n",
    "with open('../sql/init.sql') as sql_file:\n",
    "    sql_script = ''.join(sql_file.readlines())\n",
    "    with sqlite3.connect(db_fname) as conn:\n",
    "        conn.cursor().executescript(sql_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split audio files by channel; only needs to run once, takes a while\n",
    "for i in range(16):\n",
    "    for a_or_b in ['A', 'B']:\n",
    "        in_fname = '%sorig/FNL%03d%s.wav' % (audio_dir, i, a_or_b)\n",
    "        if isfile(in_fname):\n",
    "            for ch in [1, 2]: \n",
    "                out_fname = '%ssplit/%d%s.%s.wav' % \\\n",
    "                    (audio_dir, i, a_or_b, 'B' if ch == 1 else 'A')\n",
    "                subprocess.check_call(\n",
    "                    ['sox', in_fname, out_fname, 'remix', str(ch)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speakers table from spk.csv\n",
    "sql_stmt = \\\n",
    "    'INSERT INTO speakers ' \\\n",
    "    '(spk_id, gender, age, born_in, native_lang, years_edu) ' \\\n",
    "    'VALUES (?,?,?,?,?,?)'\n",
    "\n",
    "with sqlite3.connect(db_fname) as conn:\n",
    "    c = conn.cursor()\n",
    "    with open('%sspk.csv' % meta_dir, 'r') as spk_file:\n",
    "        spk_reader = csv.reader(spk_file, delimiter=',', quotechar='\"')\n",
    "        # skip header\n",
    "        next(spk_reader)\n",
    "        for row in spk_reader:\n",
    "            gender = 'f' if row[1] == 'female' else \\\n",
    "                     'm' if row[1] == 'male' else None\n",
    "            c.execute(sql_stmt, \n",
    "                      (row[0], gender, row[2], row[3], row[4], row[5]))\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sessions table from ses_tsk.csv\n",
    "sql_stmt = \\\n",
    "    'INSERT INTO sessions(ses_id, spk_id_a, spk_id_b, status) ' \\\n",
    "    'VALUES(?,?,?,?)'\n",
    "\n",
    "with sqlite3.connect(db_fname) as conn:\n",
    "    c = conn.cursor()\n",
    "    with open('%sses_tsk.csv' % meta_dir, 'r') as ses_file:\n",
    "        ses_reader = csv.reader(ses_file, delimiter=',', quotechar='\"')\n",
    "        # skip header\n",
    "        next(ses_reader)\n",
    "        for row in ses_reader:\n",
    "            if row[0][-1] == 'B':\n",
    "                # each session is listed twice, skip tasks 'B'\n",
    "                continue\n",
    "            c.execute(sql_stmt, (row[0][3:6], row[2], row[3], 0))\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tasks table from ses_tsk.csv\n",
    "sql_stmt = \\\n",
    "    'INSERT INTO tasks(tsk_id, ses_id, map_index, task_index, a_or_b) ' \\\n",
    "    'VALUES(?,?,?,?,?)'\n",
    "\n",
    "with sqlite3.connect(db_fname) as conn:\n",
    "    c = conn.cursor()\n",
    "    with open('%sses_tsk.csv' % meta_dir, 'r') as tsk_file:\n",
    "        tsk_reader = csv.reader(tsk_file, delimiter=',', quotechar='\"')\n",
    "        # skip header\n",
    "        next(tsk_reader)\n",
    "        tsk_id = 1\n",
    "        for row in tsk_reader:\n",
    "            task_index = 1 if row[0][-1] == 'A' else 2\n",
    "            a_or_b = 'A' if row[8] == 'master' else 'B'\n",
    "            c.execute(sql_stmt, \n",
    "                      (tsk_id, row[0][3:6], row[1], task_index, a_or_b))\n",
    "            tsk_id += 1\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse praat textgrid transcripts into different format\n",
    "# (code to further process that format already existed)\n",
    "for a_or_b in ['A', 'B']:\n",
    "    for i in range(16):\n",
    "        in_fname = '%sorig/%d%s_merged.TextGrid' % \\\n",
    "            (trans_dir, i, a_or_b)\n",
    "        out_fname_d = '%ssplit/%d%s_d.txt' % (trans_dir, i, a_or_b)\n",
    "        out_fname_f = '%ssplit/%d%s_f.txt' % (trans_dir, i, a_or_b)\n",
    "        if isfile(out_fname_d):\n",
    "            remove(out_fname_d)\n",
    "        if isfile(out_fname_f):\n",
    "            remove(out_fname_f)\n",
    "        \n",
    "        subprocess.check_call(['praat', '--run', \n",
    "                               '../misc/convert_transcripts.praat',\n",
    "                               in_fname, out_fname_d, '3'])\n",
    "        \n",
    "        subprocess.check_call(['praat', '--run', \n",
    "                               '../misc/convert_transcripts.praat',\n",
    "                               in_fname, out_fname_f, '4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aux function for transcript parsing; removes different markups\n",
    "def preprocess(in_item):\n",
    "    out = in_item.replace('\\n', '')\n",
    "    # @ marks unintelligible text; not very common, simply ignore\n",
    "    out = out.replace('@ ', '')\n",
    "    out = out.replace('@', '')\n",
    "    # remove markup (silence, noises)\n",
    "    while out.find('<') != -1:\n",
    "        out = out[:out.find('<')] + out[out.find('>')+1:]\n",
    "    # 'condense' double spaces\n",
    "    out = ' '.join(out.split())\n",
    "    # remove empty overlaps\n",
    "    if out == '[start_overlap][end_overlap]':\n",
    "        out = ''\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks (without features) and turns computed from transcripts\n",
    "\n",
    "sql_stmt1 = 'SELECT tsk_id, ses_id, task_index FROM tasks ORDER BY tsk_id'\n",
    "\n",
    "sql_stmt2 = \\\n",
    "    'INSERT INTO turns (tur_id, tsk_id, turn_index, speaker_role) ' \\\n",
    "    'VALUES(?,?,?,?)'\n",
    "\n",
    "sql_stmt3 = \\\n",
    "    'INSERT INTO chunks (chu_id, tur_id, chunk_index, ' \\\n",
    "    'start_time, end_time, words) VALUES(?,?,?,?,?,?)'\n",
    "\n",
    "with sqlite3.connect(db_fname) as conn:\n",
    "    c1 = conn.cursor()\n",
    "    c2 = conn.cursor()\n",
    "    c3 = conn.cursor()\n",
    "    \n",
    "    tur_ids = [0, 0]\n",
    "    chu_id = 0\n",
    "    \n",
    "    c1.execute(sql_stmt1,)\n",
    "    for tsk_id, ses_id, task_index in c1.fetchall():\n",
    "        # read both transcription files\n",
    "        lines = []\n",
    "        for d_or_f in ['d', 'f']:\n",
    "            fname = '%ssplit/%s%s_%s.txt' % \\\n",
    "                (trans_dir, ses_id, chr(64 + task_index), d_or_f)\n",
    "            with open(fname) as file:\n",
    "                lines += [[line.split()[0],\n",
    "                           line.split()[1],\n",
    "                           ' '.join(line.split()[2:]), \n",
    "                           d_or_f]\n",
    "                          for line in file.readlines()]\n",
    "        lines = [(float(l[0]), float(l[1]), preprocess(l[2]), l[3]) \n",
    "                 for l in lines]\n",
    "        lines.sort()\n",
    "        # ensure silence at the end so last chunks are processed\n",
    "        max_f = max([l[1] for l in lines if l[3] == 'f'])\n",
    "        max_d = max([l[1] for l in lines if l[3] == 'd'])\n",
    "        if max_d < max_f:\n",
    "            lines.append((max_d, max_f + 1, '', 'd'))\n",
    "            lines.append((max_f, max_f + 1, '', 'f'))\n",
    "        else:\n",
    "            lines.append((max_f, max_d + 1, '', 'f'))\n",
    "            lines.append((max_d, max_d + 1, '', 'd'))\n",
    "        \n",
    "        # arrays to track words of current chunk, start/end timestamps,  \n",
    "        # and turn/chunk counts per speaker (order: describer, follower)\n",
    "        words = ['', ''] \n",
    "        starts = [0.0, 0.0]\n",
    "        ends = [0.0, 0.0]\n",
    "        tur_cnts = [0, 0]\n",
    "        chu_cnts = [0, 0]\n",
    "        \n",
    "        # combine individual lines to chunks and turns\n",
    "        # (each line should actually be a full chunk)\n",
    "        for start, end, text, d_or_f in lines:\n",
    "            # index of current speaker in arrays (1-idx is other speaker)\n",
    "            idx = 0 if d_or_f == 'd' else 1\n",
    "            if text != '':\n",
    "                if len(words[idx]) == 0:\n",
    "                    # word after pause -> new chunk, maybe new turn\n",
    "                    if ends[1-idx] > ends[idx] \\\n",
    "                    or tur_cnts[1-idx] > tur_cnts[idx] \\\n",
    "                    or tur_cnts[idx] == 0:\n",
    "                        # new turn, update index and count\n",
    "                        tur_cnts[idx] = max(tur_cnts) + 1\n",
    "                        tur_ids[idx] = max(tur_ids) + 1\n",
    "                        chu_cnts[idx] = 1\n",
    "                    else:\n",
    "                        # continuation of old turn\n",
    "                        chu_cnts[idx] += 1\n",
    "                    starts[idx] = start\n",
    "                words[idx] += ' ' + text\n",
    "            else:\n",
    "                if len(words[idx]) != 0:\n",
    "                    # silence after some words -> chunk complete\n",
    "                    if chu_cnts[idx] == 1:\n",
    "                        # first chunk in turn; insert turn first\n",
    "                        c2.execute(\n",
    "                            sql_stmt2, \n",
    "                            (tur_ids[idx], tsk_id, tur_cnts[idx], d_or_f))\n",
    "                    chu_id += 1\n",
    "                    # chunk ended when silence started\n",
    "                    ends[idx] = start\n",
    "                    \n",
    "                    c3.execute(\n",
    "                        sql_stmt3, \n",
    "                        (chu_id, tur_ids[idx], chu_cnts[idx], starts[idx],\n",
    "                         start, words[idx]))\n",
    "                    words[idx] = ''\n",
    "                else:\n",
    "                    # continued silence, nothing to do\n",
    "                    pass\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 B\n",
      "0 2 A\n",
      "1 3 A\n",
      "1 4 B\n",
      "2 5 B\n",
      "2 6 A\n",
      "3 7 B\n",
      "3 8 A\n",
      "4 9 A\n",
      "4 10 B\n",
      "5 11 B\n",
      "5 12 A\n",
      "6 13 B\n",
      "6 14 A\n",
      "7 15 B\n",
      "7 16 A\n",
      "8 17 B\n",
      "8 18 A\n",
      "9 19 B\n",
      "9 20 A\n",
      "10 21 B\n",
      "10 22 A\n",
      "11 23 B\n",
      "11 24 A\n",
      "12 25 B\n",
      "12 26 A\n",
      "13 27 B\n",
      "13 28 A\n",
      "14 29 B\n",
      "14 30 A\n",
      "15 31 B\n",
      "15 32 A\n"
     ]
    }
   ],
   "source": [
    "# extract features for all chunks (runs a long time)\n",
    "\n",
    "sql_stmt1 = \\\n",
    "    'SELECT tsk_id, ses_id, task_index, a_or_b ' \\\n",
    "    'FROM   tasks ' \\\n",
    "    'ORDER BY tsk_id'\n",
    "\n",
    "sql_stmt2 = \\\n",
    "    'SELECT chu.chu_id, ' \\\n",
    "    '       chu.start_time, ' \\\n",
    "    '       chu.end_time, ' \\\n",
    "    '       chu.words, ' \\\n",
    "    '       tur.speaker_role ' \\\n",
    "    'FROM   chunks chu ' \\\n",
    "    'JOIN   turns tur ' \\\n",
    "    'ON     chu.tur_id == tur.tur_id ' \\\n",
    "    'WHERE  tur.tsk_id == ? ' \\\n",
    "    'ORDER BY chu.chunk_index'\n",
    "\n",
    "sql_stmt3 = \\\n",
    "    'UPDATE chunks ' \\\n",
    "    'SET    pitch_min = ?,' \\\n",
    "    '       pitch_max = ?,' \\\n",
    "    '       pitch_mean = ?,' \\\n",
    "    '       pitch_std = ?,' \\\n",
    "    '       rate_syl = ?,' \\\n",
    "    '       rate_vcd = ?,' \\\n",
    "    '       intensity_min = ?,' \\\n",
    "    '       intensity_max = ?,' \\\n",
    "    '       intensity_mean = ?,' \\\n",
    "    '       intensity_std = ?,' \\\n",
    "    '       jitter = ?,' \\\n",
    "    '       shimmer = ?,' \\\n",
    "    '       nhr = ? ' \\\n",
    "    'WHERE  chu_id = ?'\n",
    "\n",
    "with sqlite3.connect(db_fname) as conn:\n",
    "    c1 = conn.cursor()\n",
    "    c2 = conn.cursor()\n",
    "    c3 = conn.cursor()\n",
    "    \n",
    "    c1.execute(sql_stmt1,)\n",
    "    for tsk_id, ses_id, task_index, a_or_b in c1.fetchall():\n",
    "        print(ses_id, tsk_id, a_or_b)\n",
    "        fname = '%sorig/FNL%03d%s.wav' % \\\n",
    "            (audio_dir, int(ses_id), chr(64 + task_index))\n",
    "        if not isfile(fname):\n",
    "            continue\n",
    "        \n",
    "        c2.execute(sql_stmt2, (tsk_id,))\n",
    "        for chu_id, start, end, words, role in c2.fetchall():\n",
    "            # skip chunks that are too short to process\n",
    "            if end - start < 0.086:\n",
    "                continue\n",
    "            \n",
    "            file_a_or_b = 'A' if a_or_b == 'A' and role == 'd' \\\n",
    "                else 'A' if a_or_b == 'B' and role == 'f' \\\n",
    "                else 'B'\n",
    "            in_fname = '%ssplit/%s%s.%s.wav' % \\\n",
    "                (audio_dir, ses_id, chr(64 + task_index), file_a_or_b)\n",
    "            cut_fname = '%s%d_%d.wav' % (tmp_dir, tsk_id, chu_id)\n",
    "            out_fname = '%s%d_%d.txt' % (tmp_dir, tsk_id, chu_id)\n",
    "            \n",
    "            subprocess.check_call(['sox', in_fname, cut_fname, 'trim', \n",
    "                                   str(start), '=' + str(end)])\n",
    "            subprocess.check_call(['praat', '--run', \n",
    "                                   '../misc/extract_features.praat',\n",
    "                                   cut_fname, out_fname])\n",
    "\n",
    "            with open(out_fname, 'r') as out_file:\n",
    "                lines = out_file.readlines()\n",
    "                feats = {}\n",
    "                for line in lines:\n",
    "                    key, val = line.replace('\\n', '').split(',')\n",
    "                    feats[key] = val\n",
    "            remove(cut_fname)\n",
    "            remove(out_fname)\n",
    "            \n",
    "            # count occurrences per vowel, add up, divide by duration\n",
    "            rate = sum(map(words.lower().count, 'aeiou')) / (end - start)\n",
    "            \n",
    "            c3.execute(sql_stmt3, \n",
    "                       (feats['f0_min'],\n",
    "                        feats['f0_max'],\n",
    "                        feats['f0_mean'],\n",
    "                        feats['f0_std'],\n",
    "                        rate,\n",
    "                        feats['vcd2tot_frames'],\n",
    "                        feats['int_min'],\n",
    "                        feats['int_max'],\n",
    "                        feats['int_mean'],\n",
    "                        feats['int_std'],\n",
    "                        feats['jitter'],\n",
    "                        feats['shimmer'],\n",
    "                        feats['nhr'],\n",
    "                        chu_id))\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run cleanup script, mostly for null values (instead of '--undefined--')\n",
    "with open('../sql/cleanup.sql') as sql_file:\n",
    "    sql_script = ''.join(sql_file.readlines())\n",
    "    with sqlite3.connect(db_fname) as conn:\n",
    "        conn.cursor().executescript(sql_script)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
